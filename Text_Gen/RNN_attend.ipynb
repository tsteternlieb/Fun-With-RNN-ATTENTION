{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0e816129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d814992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a78ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769655da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e28d9ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "(0, 'a')\n"
     ]
    }
   ],
   "source": [
    "f,c=['a','f']\n",
    "print(c)\n",
    "for x in enumerate(f):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "acc3f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq_dataset():\n",
    "    def __init__(self, path, max_seq_len, word_embedding_model):\n",
    "        self.path = path\n",
    "        self.init_process()\n",
    "        self.max_seq_len = max_seq_len \n",
    "        self.word_embedding = word_embedding_model\n",
    "        \n",
    "        \n",
    "        \n",
    "    def init_process(self):\n",
    "        self.tokenize()\n",
    "    \n",
    "    def tokenize(self):\n",
    "        with open(self.path,'r') as f:\n",
    "            raw = f.read()\n",
    "            self.token_seq = nltk.word_tokenize(raw)\n",
    "            for idx,word in enumerate(self.token_seq):\n",
    "                self.token_seq[idx] = word.lower()\n",
    "            \n",
    "            self.len = len(self.token_seq)\n",
    "            \n",
    "    def _word_converter(self,word):\n",
    "        '''class function for exception handling when converting words to vectors'''\n",
    "        try:\n",
    "            vec = self.word_embedding[word]\n",
    "            return([vec])\n",
    "        except:\n",
    "            \n",
    "            if '-' in word:\n",
    "                try:\n",
    "                    vec = self.word_embedding[word.replace('-','')]\n",
    "                    return([vec])\n",
    "                except:  \n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    w1,w2 = word.split('-')\n",
    "                    vec1_l = self._word_converter(w1)\n",
    "                    vec2_l = self._word_converter(w2)\n",
    "                    vec1_l.extend(vec2_l)\n",
    "                    return(vec1_l)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            else:\n",
    "                print(word)\n",
    "                return(\"ndad\")\n",
    "        \n",
    "            \n",
    "                \n",
    "                \n",
    "    \n",
    "    def produce_batch(self,batch_size):\n",
    "        seq_test = []\n",
    "        for example in range(batch_size):\n",
    "            start = random.randint(0,self.len-self.max_seq_len-1)\n",
    "            stop = start+random.randint(1,self.max_seq_len)\n",
    "            slice_ = self.token_seq[start:stop]\n",
    "            \n",
    "                                    \n",
    "        return seq_test\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4625238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_data = seq_dataset('./text_folder/mobydick.txt',100,w2v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "026df914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shudffle\n",
      "[array([ 2.2832e-01,  3.4314e-01,  3.4916e-01, -6.2292e-02,  5.8088e-01,\n",
      "        7.6693e-02, -3.3078e-02,  1.8288e-01, -4.3578e-01,  4.6312e-01,\n",
      "        2.2758e-01,  6.6902e-03, -9.0716e-02,  1.0973e+00,  2.9967e-01,\n",
      "        1.4418e-01, -6.0248e-01,  4.7535e-01, -3.7224e-02, -3.6675e-01,\n",
      "        1.1219e+00, -1.2940e-01, -5.0331e-01,  5.8335e-01,  7.9264e-01,\n",
      "       -2.6178e-01, -2.3382e-01, -4.8055e-01,  8.7966e-02, -7.5332e-01,\n",
      "       -1.8990e-01,  4.4444e-01,  9.3678e-03,  4.4959e-02,  6.8601e-01,\n",
      "       -9.1632e-02, -6.7163e-01,  5.4273e-01,  2.6784e-01,  6.4011e-01,\n",
      "        6.0244e-01, -1.9369e-01,  8.2975e-02,  1.0601e-01,  4.9757e-01,\n",
      "        1.3826e-01,  4.3512e-01, -1.3030e+00, -3.0877e-01, -6.3144e-01,\n",
      "       -3.1466e-01, -2.5677e-02, -4.7305e-01,  5.7616e-01, -1.7668e-01,\n",
      "       -2.8022e+00,  3.9615e-01,  3.3021e-01,  1.5153e+00,  1.0390e+00,\n",
      "       -3.1545e-01, -1.7695e-01, -1.2297e-01, -1.3058e-01,  3.0818e-01,\n",
      "       -3.4138e-01,  3.3992e-01,  1.4005e-01, -2.1849e-01, -5.8850e-01,\n",
      "       -7.4803e-01,  4.0340e-01, -3.8642e-01, -1.0920e-03,  2.0563e-01,\n",
      "        4.7726e-01, -3.8138e-02, -5.2337e-01,  8.2651e-02,  4.9846e-02,\n",
      "        6.2978e-01,  3.3405e-01, -4.1248e-01, -4.8782e-02, -9.2659e-01,\n",
      "       -2.7725e-01,  2.4716e-01, -4.4634e-01, -9.3081e-02, -3.9981e-02,\n",
      "       -4.2962e-01,  2.8856e-04, -3.6535e-01, -6.3623e-01, -2.7466e-02,\n",
      "       -5.3548e-01,  1.3744e-01, -4.1304e-01,  4.3853e-01, -9.7321e-01],\n",
      "      dtype=float32), 'n', 'd', 'a', 'd']\n"
     ]
    }
   ],
   "source": [
    "print(moby_data._word_converter(\"double-shudffle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c9f16ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'be', 'backward', ',', 'but', 'let', 'him', 'cheerfully', 'allow', 'himself', 'to', 'spend', 'and', 'be', 'spent', 'in', 'that', 'way', '.', 'and', 'the', 'man', 'that', 'has', 'anything', 'bountifully', 'laughable', 'about', 'him', ',', 'be', 'sure', 'there', 'is', 'more', 'in', 'that', 'man', 'than']\n",
      "['as', 'howling', 'condition', 'as', 'the', 'coast', 'of', 'labrador', '.', 'as', 'it', 'is', ',', 'parts', 'of', 'her', 'back', 'country', 'are', 'enough', 'to', 'frighten', 'one', ',', 'they', 'look', 'so', 'bony', '.', 'the', 'town', 'itself', 'is', 'perhaps', 'the', 'dearest', 'place', 'to', 'live', 'in', ',', 'hi', 'all', 'new', 'england', '.', 'it', 'is', 'a', 'land', 'of', 'oil', ',', 'true', 'enough', ':']\n",
      "['the', 'double-shuffle', '!', 'throw', 'yourselves', '!', 'legs', '!', 'legs', '!', '216', 'moby-dick', 'iceland', 'sailoe', '.', 'i', 'do', \"n't\", 'like', 'your', 'floor', ',', 'maty', ';', 'it', \"'s\", 'too', 'springy', 'to', 'my', 'taste', '.', 'i', \"'m\", 'used', 'to', 'ice-floors', '.', 'i', \"'m\", 'sorry', 'to', 'throw', 'cold', 'water', 'on', 'the', 'subject', ';', 'but', 'excuse', 'me', '.', 'maltese', 'sailor', '.', 'me', 'too', ';', 'where', \"'s\", 'your', 'girls']\n",
      "['a', 'good', 'start', ',', 'when', 'the', 'landlady', 'caught', 'at', 'me', ',', 'again', 'vowing', 'i', 'should', 'not', 'break', 'down', 'her', 'premises', ';', 'but', 'i', 'tore', 'from', 'her', ',', 'and', 'with', 'a', 'sudden', 'bodily', 'rush', 'dashed', 'myself', 'full', 'against', 'the', 'mark', '.']\n",
      "['hand', 'it', 'me', 'j', 'here', \"'s\", 'a', 'hollow', '!', 'men', ',', 'ye', 'seem', 'the', 'years', ';', 'so', 'brimming', '!', 'life', 'is', 'gulped', 'and', 'gone', '.', 'steward', ',', 'refill', '!', \"'\", 'attend', 'now', ',', 'my', 'braves', '.', 'i', 'have', 'mustered', 'ye', 'all', 'round', 'this', 'capstan', ';', 'and', 'ye', ',', 'mates', ',', 'flank', 'me', 'with', 'your', 'lances', ';', 'and', 'ye', ',', 'harpooneers', ',', 'stand', 'there', 'with', 'your', 'irons', ';', 'and', 'ye', ',', 'stout', 'mariners', ',', 'ring', 'me', 'in', ',', 'that', 'i', 'may', 'in', 'some', 'sort', 'revive', 'a', 'noble', 'custom', 'of', 'my', 'fisherman', 'fathers', 'before', 'me']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_data.produce_batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b62ecc6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KeyedVectors' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b00fc7e3d7df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'KeyedVectors' object is not callable"
     ]
    }
   ],
   "source": [
    "w2v.get_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "da80944c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.25, 0.25, 0.25, 0.25]], dtype=float32)>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Softmax()(tf.ones((1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c57d6276",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(layers.Layer):\n",
    "    def __init__(self,embed_dim):\n",
    "        super(Attn, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.query = layers.Dense(embed_dim)\n",
    "        self.key = layers.Dense(embed_dim)\n",
    "        self.value = layers.Dense(embed_dim)\n",
    "        \n",
    "        self.softmax = layers.Softmax()\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        values = self.value(inputs)\n",
    "        queries = self.query(inputs)\n",
    "        keys = self.key(inputs)\n",
    "        \n",
    "        #everything is batch_size,input_len,embed_dim\n",
    "        \n",
    "        \n",
    "        similarity_scores = tf.matmul(queries,keys,transpose_b=True)/tf.sqrt(float(self.embed_dim))\n",
    "        similarity_scores = self.softmax(similarity_scores)\n",
    "        print(queries.shape, keys.shape)\n",
    "        \n",
    "        print(similarity_scores.shape,values.shape)\n",
    "        \n",
    "        out = tf.matmul(similarity_scores,values)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0fa8cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn_attend(layers.Layer):\n",
    "    def __init__(self,input_shape,vocab_size,attention_embed_dim=64):\n",
    "        super(rnn_attend,self).__init__()\n",
    "        self.bidirectional = layers.Bidirectional(layers.LSTM(10, return_sequences=True), input_shape=(5, 10))\n",
    "        self.attn = Attn(attention_embed_dim)\n",
    "        self.out = layers.Dense(vocab_size)\n",
    "        \n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.bidirectional(inputs)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.attn(x)\n",
    "        x = self.out(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbe8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
